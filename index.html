<!DOCTYPE HTML>
<html>

<head>
    <title>Dynamic Improvement</title>
    <link rel="apple-touch-icon" sizes="57x57" href="favicon/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="favicon/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="favicon/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="favicon/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="favicon/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="favicon/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="favicon/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="favicon/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192" href="favicon/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="favicon/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="favicon/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <style>
        .image.avatar img {
            border-radius: 0% !important;
        }
        @media (max-width: 600px) and (min-width:400px){
        	iframe{
        		height:300px;
        	}
        }
         @media (max-width: 399px) and (min-width:0px){
        	iframe{
        		height:auto;
        	}
        }
    </style>
</head>

<body id="top">
    <!-- Header -->
    <header id="header">
        <a href="#" class="image avatar"><img src="images/laptop.png" alt="" />
        </a>
        <h1><strong>Team Dynamic Improvement</strong></h1>
        <h1>Are Laptops a Physical Barrier Against Communication?</h1>
    </header>
    <!-- Main -->
    <div id="main">

        <!--One-->
        <section id="One">
            <h2>Our Focus<br /></h2>
            <p>
                How can a robot intervene and help individual team members communicate better by minimizing use of their laptops, and also valuing and holding each team member accountable to group discussion by not being a source of distraction?
            </p>
            <ul>
                <li>Robot should intervene when two team members are leaning over to look at the same screen and excluding the third person from discussion. </li>
                <li>Robot should rotate around to see which team members are talking and tap once on a laptop screen to encourage a confused team member to talk and tap furiously on a talkative team member’s laptop screen to stop them from talking so much. </li>
                <li>Robot should be small enough to fit between two laptops, but tall enough to see over individual laptop screens and ensure team members are not distracting themselves. </li>
            </ul>
        </section>

        <!-- Two -->
        <section id="Two">
            <h2>Preliminary Observations</h2>
            <p>On March 8, we observed students and staff at Duffield Hall working with or without laptops and saw different communication patterns exchanged between them. </p>
            <ul>
                <li>One group of construction workers used no electronic devices and appeared more attentive to each other. </li>
                <li>Students multitasked between working with their team members on their laptops and typing out messages to their friends on their phones.
                    <img src="images/duffield.jpg" alt="Duffield Hall" width="100%" height="100%" />
            </ul>
        </section>

        <!-- Three -->
        <section id="Three">
            <h2>Brainstorming Session</h2>
            <p>Each of us met up the next day to discuss how we could create an expressive robot to stop individuals from hiding behind their laptop and increase work productivity. </p>
            <ul>
                <li>How is the laptop a physical barrier to group communication?</li>
                <li>How can we increase communication between different members in a team? I.e. leader, programmer, designer, business strategist?</li>
                <li>How should the robot fit between computers?</li>
            </ul>
            <p>We felt the appearance of the robot should be a main factor of its effectiveness and appeal. We imagined the robot to be small and portable; it can be placed in the center of the table and only becomes noticeable when someone is distracted. In terms of functionality, the robot should grab user attention and bring him/her back to focus on the group work.  </p>
        </section>

        <!-- Four -->
        <section id="Four">
            <h2> Teamwork Task to Measure Individual and Group Distractedness</h2>
            <p> We created a task to focus on how individuals get distracted in a group. At the start, one of us sent all individuals a link to Flockdraw, an online drawing collaboration platform. We told three team members that they had 10-15 minutes to solve two visual brain puzzles together. They could use the online chat or talk to each other in person as well as draw out their ideas. When they finished one problem, they should all agree on the answer before typing it out in the chat box. </p>
            <h2>Instructions for Team Members</h2>
            <p>Please work together to solve two visual brain puzzles together. You have 10-20 minutes. You can use the FlockDraw drawing platform: http://flockdraw.com/8lyp0r to chat online or out loud and draw out any of your ideas with your teammates. </p>
            <ul>
                <li>Four rollerbladers exercise around separate circular paths; each path is one third of a mile in length. They start simultaneously at the black spots, with speeds of six, nine, twelve, and fifteen miles per hour. By the end of the 20 minute workout, how many times will they have simultaneously returned to the spots where they started?</li>
                <img src="images/flockdraw_1.png" />
                <li>Rearrange three golf balls so that the triangular pattern points down instead of up.</li>
                <img src="images/flockdraw_2.png" />
            </ul>
            <h2>Experimental Setup </h2>
            <p>We recruited three of our friends to participate in a social experiment at Duffield Hall. None of them had met each other before. One of our participants was a business student, while the others were engineers. At the start, we had each of them sit at an empty table, open up their laptops to an email with two questions and Flockdraw, and start discussing the problem. Two of our team members video-recorded their interactions from two different angles for ten minutes.
            </p>
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/tf31iRq3UVc" frameborder="0" allowfullscreen></iframe>

            <h2>Analysis and Coding Scheme</h2>
            <p>All of our participants engaged in channel blending where they alternated across different electronics like a calculator, smartphone, and the Flockdraw interface to solve the problems. They mainly used the calculator in their smartphone to calculate values for the first question and the Flockdraw interface to draw out their ideas. They rarely used the online chat interface, but preferred to speak their thoughts out loud. Interestingly, the two engineers talked the majority of the time. They understood how to solve the problem, but the business student felt left out and her opinion undervalued because she did not understand what was going on.</p>
            <img src="images/coding_scheme.JPG" alt="Coding Scheme" width="100%" height="100%" />
        </section>

        <!--Five-->
        <section id="Five">
            <h2>Benchmarking Mind Map</h2>
            <p>A few days later, we skyped each other and discussed ideas for what we wanted our robot to look like and what materials we might need. Originally, we decided to focus on the tapping and peering factors as a subtle way of catching people surfing social media instead of working productively on their team projects.
            </p>
            <img src="images/mindmap.png" width="80%" />
        </section>

        <!--Seven-->
        <section id="Seven">
            <h2>Initial Design Sketches</h2>
            <p>All team members sketched our some designs focusing on the tapping factor, reflecting mirror, and extended protrusions that could get team members to notice how distracted they were from work.</p>
            <h2>Lucy's Design Sketches</h2>
            <img src="images/lucy_designs.jpg" width="100%" height="100%" />
            <h2>Alex's Design Sketches</h2>
            <img src="images/alex_designs.JPG" width="100%" height="100%" />
            <h2>Kate's Design Sketches</h2>
            <img src="images/kate_designs.JPG" width="100%" height="100%" />
            <h2>Pehuen's Design Sketches</h2>
            <img src="images/pehuen_designs.JPG" width="100%" height="100%" />
            <h2>Janani's Design Sketches</h2>
            <img src="images/janani_designs.JPG" width="100%" height="100%" />
        </section>

        <!--Eight-->
        <section id="Eight">
        <h2>First Paper Robot Prototypes</h2>
        <p>A few days later, we created two paper prototype robots to explore the physical action and interaction participants might experience with the tapping motion and peering motion. The Pointer lightly taps against the computer screen when people are not paying attention, increasing in intensity depending on how distracted participants are and how long they wait before they focus</p>
        <img src="images/paper1.jpg" width="100%" height="100%"/>

        <p>The Gazer resembles two anthromoporhic eyes that rotate around to see who is paying attention (Fig 7). When someone is not paying attention, it stops and peers over their laptop screen. Moreover, it also rotates back and forth to get the person’s attention. When we experimented with participants, we realized that the robot was too annoying. Participants did not enjoy when the eyes smacked against their laptop screen and did not enjoy the vigorous eye motion across their screens. </p>
        <img src="images/paper2.jpg" width="100%" height="100%"/>

        </section>
        <!--Nine-->
        <section id="Nine">
            <h2>Reflections on Initial Design Exploration</h2>
            <p>Benchmarking was useful for clustering thoughts together and understanding what goes into building a robot i.e. materials needed, appearance, and interactivity involved with connecting input and output devices. </p>
            <p>Prototyping helps you iterate through thousands of different types of low-fidelity paper designs before moving on to medium and high-fidelity designs. </p>
            <ul>
                <li>Fail early and learn from your mistakes before it starts costing a lot to build the robot. </li>
                <li>Think about and reflect on how one motion like tapping can be implemented with a stick, pointer, or two smiling eyes. </li>
            </ul>
            <p>Test out different components of a design and see which one works. </p>
        </section>

        <!--Ten-->
        <section id="Ten">
            <h2>Reflector Cardboard Technical Implementation</h2>
            <p>We came back together and started working on creating a functional prototype with three Arudino motors, a cardboard body, two rulers, and a mirror. There are two joints in the arm of this robot, with one at the base and the other at the end of the bottom ruler. The base (red cardboard box) can also rotate. We had some trouble balancing the rotating base as the center of mass is not directly on top of the bottom motor.</p>
            <img src="images/robot_build1.JPG" width="100%" height="100%" />
            <img src="images/robot_build2.JPG" width="100%" height="100%" />
            <img src="images/robot_build3.JPG" width="100%" height="100%" />
        </section>

        <!--Eleven-->
        <section id="Eleven">
            <h2>Interactive FlowChart and Three Expressive Motions</h2>
            <p>One of our team members created an interactive flowchart that depicts how the robot interacts. Originally, the robot simply rotates 360 degrees. When it notices a team members getting distracted online, it stops in front of that person's screen. If that team member stays distracted for more than five minutes, then the robot starts tapping on the screen. If ten minutes pass, then the robot leans over the laptop to show the person a mirror reflection. Once the team member stops getting distracted, the robot resumes rotating 360 degrees and surveilling the crowd.
            </p>
            <img src="images/flowchart.png" width="100%" height="100%" />
            <p>Our three expressive behaviors are:</p>
            <ul>
                <li>Rotate 360 degrees</li>
                <li>Tap on laptop screen</li>
                <li>Lean and show mirror</li>
            </ul>
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/N440lrHkwA0" frameborder="0" allowfullscreen></iframe>
        </section>

        <!--Twelve-->
        <section id="Twelve">
        	<h2>Third CAD 3D Printed Prototype</h2>
        	<p>Two weeks later, we came back together and brainstormed ideas for a more aesthetically appealing, 3D printed model (Fig 10). We decided to go with a unique pear shape and conceal one continuous 360 degrees motor and wires inside. Then, we planned on sticking two other motors, one of which moves the arm up and down and another that pulls the string on the second arm and flicks the mirror up and down. Unfortunately, we could not get our parts 3D printed in time because we sent them to Rhodes Hall too late. But, we did end up using many of our ideas from our 3D printed model in our final prototype like concealing wires inside a wooden base and a flicking motion on the arm with the mirror attached. </p>
  			<img src="images/CAD.JPG" height="100%" width="100%"/>
        </section>

        <!--Thirteen-->
        <section id="Thirteen">
            <h2>Reflector Final Robot Design</h2>
            <p>The following were the main components of the robot:</p>
            <ul>
                <li>2 Motors
                    <ul>
                        <li>One 360 degrees continuous motor</li>
                        <li>One servo motor</li>
                    </ul>
                </li>
                <li>3 Degrees of Freedom
                    <ul>
                        <li>Rotation of base</li>
                        <li>Arm swing and mirror flick</li>
                        <li>Taunting mirror wiggle</li>
                    </ul>
                </li>
            </ul>
            <p>Moreover, we used a Bluetooth Mate Gold with a BLE app connected to an Arduino 101 board to wirelessly connect and remove extraneous wires.  The BLE application reads from the serial port and writes to the Bluetooth port on the Arduino 101 board (Fig 10). We typed in letters which triggered commands on the robot: o for open, c for close, r for right, l for left, d for decrease, i for increase, w for wiggle (Fig 11). </p>
            <img src="images/finalrobot_parts.JPG" width="100%" height="100%" />
            <img src="images/final_design1.jpg" width="100%" height="100%" />
            <img src="images/final_design2.png" width="100%" height="100%" />
        </section>

        <!--Fourteen-->
        <section id="Fourteen">
            <h2>Online Survey Process and Analysis</h2>
            <p>We used Cornell Qualtrics to create a series of demographic, analytical, and reflection questions for participants and Amazon Mechanical Turk to recruit workers to take the short survey and watch a few videos. At the beginning, we told participants what type of study and tasks they would perform. </p>
            <h2>Types of Questions Asked</h2>
            <ul>
                <li>Demographic
                    <ul>
                        <li>Age</li>
                        <li>Student status</li>
                        <li>Gender</li>
                        <li>How often do you meet in groups?</li>
                        <li>How much collaboration on laptops?</li>
                    </ul>
                </li>
                <li>Analytical with Three Video Clips
                    <ul>
                        <li>What is robot doing in the video?</li>
                        <li>Rate the degree to which the laptop formed a physical barrier.</li>
                        <li>Rate the degree to which you agree with the following statements.</li>
                        <li>What feeling did the robot express?</li>
                        <li>How confident are you about your answer (above)?</li>
                    </ul>
                </li>
                <li>Reflection
                    <ul>
                        <li>Any final thoughts or comments?</li>
                    </ul>
                </li>
            </ul>
            <h2>Demographic Online Survey Results</h2>
            <p>Out of 52 total responses, we rejected 6 responses based on fake information (i.e. k or Lorem Ipsum). Most responders were senior students (13) or graduate students (14). Ages ranged from 18-22 (17) to 36-64 (1). 24 participants identified themselves as Male, while 20 identified as Female. </p>
            <p>29% of participants felt the statement that they met with others to perform collaborative work, described them very well, and 29% felt it described them moderately well. </p>
            <img src="images/Q4_GroupFrequency.png" width="100%" height="100%" />
            <p>Interestingly, participants varied in how much work they did on laptops. </p>
            <img src="images/Q5_CollaborationLaptops.png" width="100%" height="100%" />
            
            <h2>Rotating Motion</h2>
            <p>Our first video clip showed the robot alternating between fast and slow movement. Many participants (20) felt the robot was scanning and searching. 15 participants felt the robot was rotating around, while 4 participants had no idea. Interestingly, we received 5 lorem ipsum responses due to our acceptance of all workers including bots with 0% approval ratings.</p>
            <p>One participant mentioned, “I wouldn't be able to tell you anything but spin without the title. With the word "Reflector" title, I think it is intended to distract members by catching their attention, similarly to how reflective vests work for construction workers and biker/runners at night.”</p>
            <p>Another participant mentioned, “It seemed like the robot was making rounds to point at some group members? The first section of the clip did not seem like it had a target. In the second cut, the robot was moving to point at the other person (orange shirt)/his laptop”</p>
            
            <img src="images/RotateRobot_Ratings.png" width="100%" height="100%" />
            <img src="images/RotateRobot_Feelings.png" width="100%" height="100%" />
            <img src="images/Rotate_robot_InterpretationFeeling.png" width="100%" height="100%" />
           
            <p>12 participants did not notice the robot changed speeds, while 22 participants did notice the robot changed speeds from fast to slow. Out of those 22 participants, 2 participants wanted a medium speed, 10 participants liked the slower speed, and the rest of the 10 preferred the fast speed. </p>
            <p>One participant mentioned, “Yes, but I would have preferred a speed in between. The fast speed was too noisy and distracting, and the slow speed seems like it will take the robot too long to get somewhere. But if forced to choose, slow is better, as it's less distracting.”</p>
            <p>Another participant said, “As long as the speed is uniform and it doesn't accelerate so I get used to it and don't get distracted”</p>
            <h2>Flicking Arm and Mirror Tilt Motion</h2>
            <p>25 participants felt the robot that flicked it’s armed out and tilted the mirror was drawing attention to the distracted team member. </p>
            <p>One participant mentioned that the robot was trying to, “Get the attention of the distracted student, re-focus the student on the task at hand.”</p>
            <p>23 participants felt that one of the team members was distracted and the robot was trying to wave to get his attention. People thought the robot “tapped” or “pointed in the direction” or “showed its arm” at the distracted team member. </p>
            <p>Interestingly, one participant noted that “I don't think the members reacted much but I think it would be distracting. It may be better if the robot communicated attention back to the task in a more discrete method such as a vibrating bluetooth watch strap or light indicator on the object of interest. The sound of the robot moving along with visual view for me would be distracting.”</p>
           
            <img src="images/RobotFlickarm_ratings.png" width="100%" height="100%" />
            <img src="images/robotflickarm_expressedfeeling.png" width="100%" height="100%" />
            <img src="images/flickarm_interpret.png" width="100%" height="100%" />
           
            <h2>Overview of Field Study Process</h2>
            <p>We did two comparative field studies. </p>
            <p>Study 1 - We bought in random participants and asked them to work on a specified task we gave them. Our motivation was to observe how people who have not worked together before performed a task and to which extent robotic intervention would be required. One team member participated in the field study to purposely be distracted during activity and observe others’ response to the robot movement</p>

             <iframe width="100%" height="500px" src="https://www.youtube.com/embed/1K9v7ozKUcw" frameborder="0" allowfullscreen></iframe>

            <p>Study 2 - We bought in a team of 3 members who were working on a semester long class project. It was obvious to note that they were very comfortable with each other and dived into working together immediately. They had their light fun moments working together on their project and our aim to observe where we could intervene was made more clearer. </p>
            
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/ux7bch0LDAA" frameborder="0" allowfullscreen></iframe>
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/iizF7wyYkwo" frameborder="0" allowfullscreen></iframe>

            <h2>Field Study Results</h2>
            <ul>
                <li>The robot grabbed people’s attention</li>
                <li>Some movements were too fast and sudden, a little distractive to the team activity</li>
                <li>When the arm was purposely triggered, participants noticed it but did not comment on the behaviour</li>
                <li>FlockDraw was difficult to use, so participants switched to using scratch paper</li>
                <li>Diverted attention from laptop screens</li>
            </ul>
            <p>The participants were very comfortable working with each other as they were all already familiar. The robot grabbed their attention and participants thought it was very cool! One of the participants mentioned that the sudden movement of the arm startled him. One of the participants mid-way through the discussion, started using Snapchat. Though the robot looked at him and raised its arm, he was unsure what it meant. Felt the meaning of looking was unclear.</p>
        </section>

        <!--Fifteen-->
        <section id="Fifteen">
            <h2>Final Reflections</h2> What we learned:
            <ul>
                <li>Comparing Study 1 and 2, we observed that in cases where the teams were random and the task assigned, the participants tended to work more and be less distracted.</li>
                <li>In Study 2, the participants knew each other well and after a point started looking at Snapchat and other such social media, which gave us cause to use the robot more often.</li>
            </ul>
            <h2>Future Improvements</h2>
            <p>We would like to create different sized robots and testing them on different tables. In our field study, participants often moved laptops further apart when they realized our large robot was getting stuck between their laptops. Moreover, we are also interested in quieter motors and smoother movements of the arm. Our current arm flick and mirror tilt is very abrupt, so much so that one participant even put his arm up to stop the mirror from seeing him. Lastly, we plan on adding mobility with a moving base to move towards distracted participants and stop the robot from getting stuck between laptops.</p>
            <img src="images/poster.png" width="100%" height="100%" />
        </section>

        <!-- Sixteen -->
        <section id="Sixteen">
            <h2>Design Project II videos</h2>
            <!-- Alex -->

            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/pTeXi_QbZms" frameborder="0" allowfullscreen></iframe>
            <h3>Alex</h3>
            <!-- <p>Drawing tool with arduino.</p> -->

            <!-- Lucy -->
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/KqN0v2CgX_0" frameborder="0" allowfullscreen></iframe>
            <h3>Lucy</h3>

            <!-- Yu Meng -->
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/KOrkc2wSehM" frameborder="0" allowfullscreen></iframe>
            <h3>Yu Meng</h3>
            <!-- <p>Tri-Arm Robot</p> -->

            <!-- Janani -->
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/nTtD-Y3l7hA" frameborder="0" allowfullscreen></iframe>
            <h3>Janani</h3>
            <!-- <p>Kirby Robot</p> -->

            <!-- Pehuen -->
            <iframe width="100%" height="500px" src="https://www.youtube.com/embed/cQjUlOIpXek" frameborder="0" allowfullscreen></iframe>
            <h3>Pehuen</h3>
            <!-- <p>Wally Re-incarnated</p> -->
        </section>

        <!-- Team Member Images -->
        <section id="three">
            <h2>Team members</h2>
            <div class="box alt">
                <div class="row 50% uniform">
                    <div class="4u"><span class="image fit"><img src="images/alex.png" alt="alex" /></span>Alex - as898</div>
                    <div class="4u"><span class="image fit"><img src="images/lucy.png" alt="lucy" /></span>Lucy - lh486</div>
                    <div class="4u"><span class="image fit"><img src="images/janani.png" alt="janani" /></span>Janani - ju48</div>
                </div>
                <div class="row 50% uniform">
                    <div class="4u"><span class="image fit"><img src="images/yumeng.png" alt="yu meng" /></span>Kate - ykz2</div>
                    <div class="4u"><span class="image fit"><img src="images/pehuen.png" alt="pehuen" /></span>Pehuen - ppm44</div>
                </div>
            </div>
        </section>
    </div>

    <footer id="footer">
        <ul class="icons">
            <li><a href="https://github.com/lucy-he/DesignProject4/tree/gh-pages" class="icon fa-github"><span class="label">Github</span></a>
            </li>
            <li><a href="lh486@cornell.edu" class="icon fa-envelope-o"><span class="label">Email</span></a>
            </li>
        </ul>
        <ul class="copyright">
            <li>Design: Alex and Lucy</li>
        </ul>
    </footer>

    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.poptrox.min.js"></script>
    <script src="assets/js/skel.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
</body>

</html>